{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from src.utils.get_model_and_data import get_model_and_data\n",
    "from src.utils.collate_fn_coco import collate_fn_coco\n",
    "\n",
    "import clip\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=16.39s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.01s)\n",
      "creating index...\n",
      "index created!\n",
      "train set scale: 21391\n",
      "loading annotations into memory...\n",
      "Done (t=0.46s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "val set scale: 925\n"
     ]
    }
   ],
   "source": [
    "parameters = {'device': 'cuda', 'num_attentionLayer': 4}\n",
    "model, datasets = get_model_and_data(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.4102,  0.2682,  0.1940,  0.3444, -0.3625, -0.2587,  0.2043, -0.0074,\n",
      "         0.4250,  0.2670, -0.2422,  0.0995, -0.1053,  0.2691,  0.1917,  0.0509,\n",
      "        -0.4827,  0.4177, -0.3445, -0.1419,  0.3950,  0.3859, -0.2326, -0.3219,\n",
      "         0.1300, -0.2011,  0.4573,  0.2581, -0.3400,  0.4907,  0.2091,  0.0154,\n",
      "        -0.3823, -0.2245,  0.1604, -0.0080,  0.2904, -0.2357, -0.0766,  0.1977,\n",
      "        -0.4663, -0.1105,  0.1067, -0.4749, -0.4512,  0.2735, -0.0761,  0.4904,\n",
      "         0.2183,  0.2288, -0.0129,  0.3778,  0.4483, -0.1360, -0.1407,  0.0292,\n",
      "         0.2943, -0.3340, -0.4783,  0.3439,  0.0129, -0.4978,  0.3718,  0.4238,\n",
      "        -0.1644, -0.2898,  0.0070, -0.1481,  0.0833,  0.1729,  0.0495, -0.1772,\n",
      "        -0.0186,  0.4489,  0.1829,  0.3136, -0.3889,  0.2074, -0.1444,  0.1012,\n",
      "        -0.0706,  0.0627, -0.4897,  0.2038, -0.4887, -0.1778,  0.3594,  0.1729,\n",
      "         0.0929, -0.3091,  0.1724,  0.2914, -0.1149, -0.4845, -0.0167,  0.1478,\n",
      "        -0.2010,  0.0380,  0.0712,  0.3961, -0.0727, -0.2021, -0.0588,  0.4840,\n",
      "        -0.2857, -0.1606,  0.3153,  0.1733,  0.2498,  0.1351, -0.0137, -0.3839,\n",
      "         0.1776, -0.0631, -0.2186,  0.0633,  0.4812, -0.2246,  0.0871, -0.0554,\n",
      "        -0.0538,  0.4538, -0.2937, -0.2871,  0.4759, -0.4990, -0.3344,  0.4291,\n",
      "        -0.2697, -0.4893, -0.2749,  0.3729, -0.3187, -0.3814,  0.1264, -0.3856,\n",
      "        -0.4004,  0.1253, -0.4301,  0.1215,  0.4295, -0.2235,  0.4811, -0.3211,\n",
      "         0.3433, -0.1874, -0.2242,  0.3829, -0.4825, -0.1623,  0.0088,  0.4191,\n",
      "        -0.3669,  0.1940, -0.2293, -0.2244,  0.4043,  0.0332, -0.0049, -0.3435,\n",
      "        -0.3451,  0.4367,  0.0859, -0.4100,  0.2256,  0.2712, -0.3376,  0.4376,\n",
      "        -0.0356,  0.4812, -0.3419,  0.4591, -0.3929,  0.4152, -0.3487, -0.0895,\n",
      "        -0.2461,  0.1310, -0.2095,  0.3345,  0.0888,  0.1169,  0.4290, -0.4536,\n",
      "        -0.0813,  0.3523,  0.1389, -0.3384,  0.2423, -0.0551, -0.0406, -0.1610,\n",
      "         0.4014, -0.0465,  0.1486,  0.3542, -0.4306, -0.2673, -0.4152, -0.1121,\n",
      "        -0.3186, -0.2603, -0.4640,  0.0549, -0.1831,  0.4731,  0.3734, -0.0966,\n",
      "        -0.2585,  0.2265,  0.0669, -0.4896,  0.1176, -0.0830, -0.1419, -0.1319,\n",
      "         0.2756,  0.1233,  0.3914, -0.3888,  0.4872, -0.2549, -0.3155,  0.4421,\n",
      "        -0.1747,  0.1522, -0.4540,  0.4113,  0.0113, -0.1539,  0.3213, -0.3840,\n",
      "         0.2612,  0.1077,  0.1490, -0.4144,  0.3443,  0.1439,  0.2697,  0.3904,\n",
      "         0.2336,  0.4254, -0.3019, -0.2719,  0.1137, -0.3153,  0.4455, -0.2034,\n",
      "         0.3288, -0.1885, -0.0771, -0.1903, -0.1816,  0.4710,  0.0885,  0.4437,\n",
      "        -0.3499, -0.4996,  0.4871,  0.4127,  0.3290, -0.0800, -0.0073, -0.4718,\n",
      "        -0.0327, -0.0365, -0.4551, -0.4724, -0.3808,  0.0892,  0.4046,  0.3122,\n",
      "        -0.2002, -0.3485,  0.0210, -0.0455, -0.2509, -0.3387, -0.3072,  0.3638,\n",
      "         0.3034, -0.3627, -0.2100,  0.2244, -0.0987, -0.4603,  0.4701,  0.1882,\n",
      "         0.0641,  0.1240,  0.4809,  0.1000, -0.3711, -0.1348,  0.3017,  0.2086,\n",
      "         0.4060,  0.4817, -0.0835,  0.3859,  0.1354,  0.3290, -0.2927, -0.1154,\n",
      "        -0.3302, -0.2004,  0.3154,  0.1698, -0.0401, -0.0422, -0.3160, -0.0788,\n",
      "         0.3055, -0.3018,  0.4829,  0.1340,  0.4743,  0.1377,  0.3546, -0.2642,\n",
      "        -0.4167, -0.1023,  0.2683,  0.4287,  0.1876,  0.1801,  0.2624,  0.2744,\n",
      "        -0.1169,  0.3251,  0.0678, -0.2255, -0.2448, -0.4573,  0.2774,  0.0562,\n",
      "        -0.4877, -0.3674, -0.3009, -0.2662,  0.2622, -0.4055,  0.2088, -0.1238,\n",
      "         0.2008,  0.4618, -0.1001, -0.3111,  0.2388,  0.2416,  0.0141, -0.3350,\n",
      "        -0.4504,  0.1786,  0.0318,  0.0297, -0.4397,  0.3280,  0.0956, -0.2318,\n",
      "        -0.0702,  0.2984,  0.1279,  0.3488,  0.4997,  0.2996,  0.0975,  0.3920,\n",
      "        -0.2736, -0.1220, -0.0765, -0.3265, -0.2087,  0.4767,  0.1476,  0.4024,\n",
      "        -0.4741, -0.2360,  0.4695, -0.3224, -0.1477, -0.2426,  0.1924, -0.2653,\n",
      "        -0.1937,  0.4308, -0.4416, -0.4877,  0.3331,  0.4015,  0.0180, -0.3207,\n",
      "        -0.1173, -0.0448, -0.3625, -0.4230,  0.1872, -0.3266, -0.3156, -0.4104,\n",
      "         0.3675,  0.0158, -0.1569,  0.0298, -0.1871,  0.3810,  0.2357,  0.0102,\n",
      "         0.4191,  0.1056, -0.3136, -0.0128,  0.3752, -0.1857, -0.4718, -0.1346,\n",
      "         0.2178,  0.4615, -0.2687, -0.2733, -0.0527,  0.4259, -0.0837,  0.2042,\n",
      "        -0.4172,  0.1597, -0.0944, -0.4688, -0.1332,  0.3168, -0.1942, -0.0303,\n",
      "         0.0664, -0.4726, -0.1888, -0.4527, -0.0599, -0.0120, -0.3324, -0.3877,\n",
      "         0.4547, -0.4069,  0.4628,  0.0257,  0.1956,  0.0142,  0.0331, -0.3959,\n",
      "        -0.3318, -0.4091,  0.2547, -0.4944,  0.4872, -0.2886, -0.3788, -0.0094,\n",
      "         0.1254, -0.3741,  0.3564,  0.1146, -0.2822, -0.3675, -0.0964,  0.3512,\n",
      "         0.1151, -0.3365, -0.0322, -0.0649, -0.4811,  0.1955, -0.1415,  0.4984,\n",
      "         0.0732, -0.4516, -0.2909, -0.4111, -0.0988,  0.2258, -0.2253, -0.4871,\n",
      "         0.2535, -0.3372, -0.3537, -0.4702,  0.0026, -0.1390, -0.0503, -0.1161,\n",
      "         0.4905,  0.2492,  0.2198, -0.2781, -0.4985,  0.0555, -0.3302,  0.2528,\n",
      "         0.4820,  0.4165, -0.3458,  0.1706,  0.1409, -0.1746, -0.3292, -0.2861,\n",
      "         0.1215, -0.1684,  0.0720, -0.2340, -0.3565,  0.4856, -0.2157,  0.0190],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.named_parameters():\n",
    "    if k == 'encoder.bbox_embedding.bias':\n",
    "        print(v)\n",
    "#     if v.requires_grad:\n",
    "#         print(k, '\\t', v.shape, '\\t', v.numel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motionclip",
   "language": "python",
   "name": "motionclip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
